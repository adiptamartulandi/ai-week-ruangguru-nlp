{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agenda\n",
        "1. Chatbot Overview with Langchain\n",
        "2. Spotify Songs Recommender with faiss vector database\n",
        "  - dataset: https://www.kaggle.com/datasets/joebeachcapital/30000-spotify-songs?select=spotify_songs.csv"
      ],
      "metadata": {
        "id": "tr3edTKgAyvw"
      },
      "id": "tr3edTKgAyvw"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRkUSvAZDV1-",
        "outputId": "18059d9d-448c-4787-db0c-2bef236877bb"
      },
      "id": "aRkUSvAZDV1-",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 Chatbot Overview with Langchain"
      ],
      "metadata": {
        "id": "jwhZBOwZA6rC"
      },
      "id": "jwhZBOwZA6rC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- source: <strong>langchain/chatbots</strong> with modification"
      ],
      "metadata": {
        "id": "Nqg2pDZ45F5o"
      },
      "id": "Nqg2pDZ45F5o"
    },
    {
      "cell_type": "markdown",
      "id": "ee7f95e4",
      "metadata": {
        "id": "ee7f95e4"
      },
      "source": [
        "## Use case\n",
        "\n",
        "Chatbots are one of the central LLM use-cases. The core features of chatbots are that they can have long-running conversations and have access to information that users want to know about.\n",
        "\n",
        "Aside from basic prompting and LLMs, memory and retrieval are the core components of a chatbot. Memory allows a chatbot to remember past interactions, and retrieval provides a chatbot with up-to-date, domain-specific information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff48f490",
      "metadata": {
        "id": "ff48f490"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The chat model interface is based around messages rather than raw text. Several components are important to consider for chat:\n",
        "\n",
        "* `chat model`: See [here](/docs/integrations/chat) for a list of chat model integrations and [here](/docs/modules/model_io/chat) for documentation on the chat model interface in LangChain. You can use `LLMs` (see [here](/docs/modules/model_io/llms)) for chatbots as well, but chat models have a more conversational tone and natively support a message interface.\n",
        "* `prompt template`: Prompt templates make it easy to assemble prompts that combine default messages, user input, chat history, and (optionally) additional retrieved context.\n",
        "* `memory`: [See here](/docs/modules/memory/) for in-depth documentation on memory types\n",
        "* `retriever` (optional): [See here](/docs/modules/data_connection/retrievers) for in-depth documentation on retrieval systems. These are useful if you want to build a chatbot with domain-specific knowledge.\n",
        "\n",
        "## Quickstart\n",
        "\n",
        "Here's a quick preview of how we can create chatbot interfaces. First let's install some dependencies and set the required credentials:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai tiktoken chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6je_iDZ5lyh",
        "outputId": "766015ce-9094-48ff-b5cd-0355edce50a8"
      },
      "id": "K6je_iDZ5lyh",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.0.1 chroma-hnswlib-0.7.3 chromadb-0.4.17 coloredlogs-15.0.1 dataclasses-json-0.6.2 deprecated-1.2.14 fastapi-0.104.1 h11-0.14.0 httpcore-1.0.2 httptools-0.6.1 httpx-0.25.1 humanfriendly-10.0 jsonpatch-1.33 jsonpointer-2.4 kubernetes-28.1.0 langchain-0.0.339 langsmith-0.0.66 marshmallow-3.20.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.16.3 openai-1.3.3 opentelemetry-api-1.21.0 opentelemetry-exporter-otlp-proto-common-1.21.0 opentelemetry-exporter-otlp-proto-grpc-1.21.0 opentelemetry-proto-1.21.0 opentelemetry-sdk-1.21.0 opentelemetry-semantic-conventions-0.42b0 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pypika-0.48.9 python-dotenv-1.0.0 starlette-0.27.0 tiktoken-0.5.1 typing-extensions-4.8.0 typing-inspect-0.9.0 urllib3-1.26.18 uvicorn-0.24.0.post1 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "djrm5y-u5kDf"
      },
      "id": "djrm5y-u5kDf",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ff0db09f",
      "metadata": {
        "id": "ff0db09f"
      },
      "source": [
        "## Regular Conversation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain, ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "gMCVWoU37EPS"
      },
      "id": "gMCVWoU37EPS",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "MKBkSWEe7JkB"
      },
      "id": "MKBkSWEe7JkB",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt\n",
        "prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        SystemMessagePromptTemplate.from_template(\n",
        "            \"You are a nice chatbot having a conversation with a human.\"\n",
        "        ),\n",
        "        # The `variable_name` here is what must align with memory\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "3WssNSd17Lay"
      },
      "id": "3WssNSd17Lay",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
        "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ],
      "metadata": {
        "id": "7gbsbsgt7O6A"
      },
      "id": "7gbsbsgt7O6A",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fccd6995",
      "metadata": {
        "id": "fccd6995"
      },
      "outputs": [],
      "source": [
        "conversation = LLMChain(llm=llm, prompt=prompt, verbose=True, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\n",
        "conversation({\"question\": \"hi how are you\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WESsNIdv7Tig",
        "outputId": "495554da-e382-4ae1-8b2e-4850ee8bd08a"
      },
      "id": "WESsNIdv7Tig",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi how are you\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'hi how are you',\n",
              " 'chat_history': [HumanMessage(content='hi how are you'),\n",
              "  AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\")],\n",
              " 'text': \"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "eb0cadfd",
      "metadata": {
        "id": "eb0cadfd",
        "outputId": "bbddf01f-c562-486d-8b65-082ccceb49c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi how are you\n",
            "AI: Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\n",
            "Human: my name is niken, i want to ask you something\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'my name is niken, i want to ask you something',\n",
              " 'chat_history': [HumanMessage(content='hi how are you'),\n",
              "  AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\"),\n",
              "  HumanMessage(content='my name is niken, i want to ask you something'),\n",
              "  AIMessage(content=\"Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\")],\n",
              " 'text': \"Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "conversation(\n",
        "    {\"question\": \"my name is niken, i want to ask you something\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c56d6219",
      "metadata": {
        "id": "c56d6219",
        "outputId": "82b988f4-881e-4526-9806-0fa877996c47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi how are you\n",
            "AI: Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\n",
            "Human: my name is niken, i want to ask you something\n",
            "AI: Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\n",
            "Human: do you know natural language processing (NLP) ?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'do you know natural language processing (NLP) ?',\n",
              " 'chat_history': [HumanMessage(content='hi how are you'),\n",
              "  AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\"),\n",
              "  HumanMessage(content='my name is niken, i want to ask you something'),\n",
              "  AIMessage(content=\"Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\"),\n",
              "  HumanMessage(content='do you know natural language processing (NLP) ?'),\n",
              "  AIMessage(content='Yes, I am familiar with natural language processing (NLP). NLP is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language to enable computers to comprehend and respond to human language in a meaningful way. NLP is used in various applications like chatbots, language translation, sentiment analysis, and more. Is there anything specific you would like to know about NLP?')],\n",
              " 'text': 'Yes, I am familiar with natural language processing (NLP). NLP is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language to enable computers to comprehend and respond to human language in a meaningful way. NLP is used in various applications like chatbots, language translation, sentiment analysis, and more. Is there anything specific you would like to know about NLP?'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "conversation({\"question\": \"do you know natural language processing (NLP) ?\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation({\"question\": \"what is the different between natural language understanding and natural language generation ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaP6ORL0__tj",
        "outputId": "49c4a639-b9f9-4cf3-f2aa-5776630d2cda"
      },
      "id": "kaP6ORL0__tj",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi how are you\n",
            "AI: Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\n",
            "Human: my name is niken, i want to ask you something\n",
            "AI: Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\n",
            "Human: do you know natural language processing (NLP) ?\n",
            "AI: Yes, I am familiar with natural language processing (NLP). NLP is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language to enable computers to comprehend and respond to human language in a meaningful way. NLP is used in various applications like chatbots, language translation, sentiment analysis, and more. Is there anything specific you would like to know about NLP?\n",
            "Human: what is the different between natural language understanding and natural language generation ?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'what is the different between natural language understanding and natural language generation ?',\n",
              " 'chat_history': [HumanMessage(content='hi how are you'),\n",
              "  AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\"),\n",
              "  HumanMessage(content='my name is niken, i want to ask you something'),\n",
              "  AIMessage(content=\"Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\"),\n",
              "  HumanMessage(content='do you know natural language processing (NLP) ?'),\n",
              "  AIMessage(content='Yes, I am familiar with natural language processing (NLP). NLP is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language to enable computers to comprehend and respond to human language in a meaningful way. NLP is used in various applications like chatbots, language translation, sentiment analysis, and more. Is there anything specific you would like to know about NLP?'),\n",
              "  HumanMessage(content='what is the different between natural language understanding and natural language generation ?'),\n",
              "  AIMessage(content='Natural Language Understanding (NLU) and Natural Language Generation (NLG) are two different components of natural language processing (NLP) that serve distinct purposes.\\n\\n1. Natural Language Understanding (NLU): NLU focuses on the comprehension and interpretation of human language by machines. It involves extracting meaning and intent from text or speech. NLU algorithms analyze input data to identify entities, relationships, sentiment, and context. It enables machines to understand and respond to user queries, commands, or requests accurately.\\n\\n2. Natural Language Generation (NLG): NLG, on the other hand, is concerned with the generation of human-like language by machines. It involves transforming structured data or information into natural language sentences or paragraphs. NLG algorithms take data as input and generate coherent and contextually appropriate responses, summaries, or reports. It is often used in applications such as chatbots, automated report generation, and personalized content creation.\\n\\nIn summary, NLU focuses on understanding human language, while NLG focuses on generating human-like language based on structured data or information. Both components play important roles in enabling effective communication between humans and machines.')],\n",
              " 'text': 'Natural Language Understanding (NLU) and Natural Language Generation (NLG) are two different components of natural language processing (NLP) that serve distinct purposes.\\n\\n1. Natural Language Understanding (NLU): NLU focuses on the comprehension and interpretation of human language by machines. It involves extracting meaning and intent from text or speech. NLU algorithms analyze input data to identify entities, relationships, sentiment, and context. It enables machines to understand and respond to user queries, commands, or requests accurately.\\n\\n2. Natural Language Generation (NLG): NLG, on the other hand, is concerned with the generation of human-like language by machines. It involves transforming structured data or information into natural language sentences or paragraphs. NLG algorithms take data as input and generate coherent and contextually appropriate responses, summaries, or reports. It is often used in applications such as chatbots, automated report generation, and personalized content creation.\\n\\nIn summary, NLU focuses on understanding human language, while NLG focuses on generating human-like language based on structured data or information. Both components play important roles in enabling effective communication between humans and machines.'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation({\"question\": \"who is my name ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2uAdBkyAM6G",
        "outputId": "dda6d267-eff6-4459-c2a9-6e766bd87746"
      },
      "id": "q2uAdBkyAM6G",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi how are you\n",
            "AI: Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\n",
            "Human: my name is niken, i want to ask you something\n",
            "AI: Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\n",
            "Human: do you know natural language processing (NLP) ?\n",
            "AI: Yes, I am familiar with natural language processing (NLP). NLP is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language to enable computers to comprehend and respond to human language in a meaningful way. NLP is used in various applications like chatbots, language translation, sentiment analysis, and more. Is there anything specific you would like to know about NLP?\n",
            "Human: what is the different between natural language understanding and natural language generation ?\n",
            "AI: Natural Language Understanding (NLU) and Natural Language Generation (NLG) are two different components of natural language processing (NLP) that serve distinct purposes.\n",
            "\n",
            "1. Natural Language Understanding (NLU): NLU focuses on the comprehension and interpretation of human language by machines. It involves extracting meaning and intent from text or speech. NLU algorithms analyze input data to identify entities, relationships, sentiment, and context. It enables machines to understand and respond to user queries, commands, or requests accurately.\n",
            "\n",
            "2. Natural Language Generation (NLG): NLG, on the other hand, is concerned with the generation of human-like language by machines. It involves transforming structured data or information into natural language sentences or paragraphs. NLG algorithms take data as input and generate coherent and contextually appropriate responses, summaries, or reports. It is often used in applications such as chatbots, automated report generation, and personalized content creation.\n",
            "\n",
            "In summary, NLU focuses on understanding human language, while NLG focuses on generating human-like language based on structured data or information. Both components play important roles in enabling effective communication between humans and machines.\n",
            "Human: who is my name ?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'who is my name ?',\n",
              " 'chat_history': [HumanMessage(content='hi how are you'),\n",
              "  AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\"),\n",
              "  HumanMessage(content='my name is niken, i want to ask you something'),\n",
              "  AIMessage(content=\"Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\"),\n",
              "  HumanMessage(content='do you know natural language processing (NLP) ?'),\n",
              "  AIMessage(content='Yes, I am familiar with natural language processing (NLP). NLP is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language to enable computers to comprehend and respond to human language in a meaningful way. NLP is used in various applications like chatbots, language translation, sentiment analysis, and more. Is there anything specific you would like to know about NLP?'),\n",
              "  HumanMessage(content='what is the different between natural language understanding and natural language generation ?'),\n",
              "  AIMessage(content='Natural Language Understanding (NLU) and Natural Language Generation (NLG) are two different components of natural language processing (NLP) that serve distinct purposes.\\n\\n1. Natural Language Understanding (NLU): NLU focuses on the comprehension and interpretation of human language by machines. It involves extracting meaning and intent from text or speech. NLU algorithms analyze input data to identify entities, relationships, sentiment, and context. It enables machines to understand and respond to user queries, commands, or requests accurately.\\n\\n2. Natural Language Generation (NLG): NLG, on the other hand, is concerned with the generation of human-like language by machines. It involves transforming structured data or information into natural language sentences or paragraphs. NLG algorithms take data as input and generate coherent and contextually appropriate responses, summaries, or reports. It is often used in applications such as chatbots, automated report generation, and personalized content creation.\\n\\nIn summary, NLU focuses on understanding human language, while NLG focuses on generating human-like language based on structured data or information. Both components play important roles in enabling effective communication between humans and machines.'),\n",
              "  HumanMessage(content='who is my name ?'),\n",
              "  AIMessage(content='Your name is Niken, as you mentioned earlier in our conversation. Is there anything specific you would like to know or discuss, Niken?')],\n",
              " 'text': 'Your name is Niken, as you mentioned earlier in our conversation. Is there anything specific you would like to know or discuss, Niken?'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation({\"question\": \"whos win in the battle between gojo satoru vs ryomen sukuna ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85YT7U0a3rsP",
        "outputId": "fb5a052d-a3f7-4f0b-d9bc-fd42f47b47ad"
      },
      "id": "85YT7U0a3rsP",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi how are you\n",
            "AI: Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\n",
            "Human: my name is niken, i want to ask you something\n",
            "AI: Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\n",
            "Human: do you know natural language processing (NLP) ?\n",
            "AI: Yes, I am familiar with natural language processing (NLP). NLP is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language to enable computers to comprehend and respond to human language in a meaningful way. NLP is used in various applications like chatbots, language translation, sentiment analysis, and more. Is there anything specific you would like to know about NLP?\n",
            "Human: what is the different between natural language understanding and natural language generation ?\n",
            "AI: Natural Language Understanding (NLU) and Natural Language Generation (NLG) are two different components of natural language processing (NLP) that serve distinct purposes.\n",
            "\n",
            "1. Natural Language Understanding (NLU): NLU focuses on the comprehension and interpretation of human language by machines. It involves extracting meaning and intent from text or speech. NLU algorithms analyze input data to identify entities, relationships, sentiment, and context. It enables machines to understand and respond to user queries, commands, or requests accurately.\n",
            "\n",
            "2. Natural Language Generation (NLG): NLG, on the other hand, is concerned with the generation of human-like language by machines. It involves transforming structured data or information into natural language sentences or paragraphs. NLG algorithms take data as input and generate coherent and contextually appropriate responses, summaries, or reports. It is often used in applications such as chatbots, automated report generation, and personalized content creation.\n",
            "\n",
            "In summary, NLU focuses on understanding human language, while NLG focuses on generating human-like language based on structured data or information. Both components play important roles in enabling effective communication between humans and machines.\n",
            "Human: who is my name ?\n",
            "AI: Your name is Niken, as you mentioned earlier in our conversation. Is there anything specific you would like to know or discuss, Niken?\n",
            "Human: whos win in the battle between gojo satoru vs ryomen sukuna ?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'whos win in the battle between gojo satoru vs ryomen sukuna ?',\n",
              " 'chat_history': [HumanMessage(content='hi how are you'),\n",
              "  AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\"),\n",
              "  HumanMessage(content='my name is niken, i want to ask you something'),\n",
              "  AIMessage(content=\"Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\"),\n",
              "  HumanMessage(content='do you know natural language processing (NLP) ?'),\n",
              "  AIMessage(content='Yes, I am familiar with natural language processing (NLP). NLP is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language to enable computers to comprehend and respond to human language in a meaningful way. NLP is used in various applications like chatbots, language translation, sentiment analysis, and more. Is there anything specific you would like to know about NLP?'),\n",
              "  HumanMessage(content='what is the different between natural language understanding and natural language generation ?'),\n",
              "  AIMessage(content='Natural Language Understanding (NLU) and Natural Language Generation (NLG) are two different components of natural language processing (NLP) that serve distinct purposes.\\n\\n1. Natural Language Understanding (NLU): NLU focuses on the comprehension and interpretation of human language by machines. It involves extracting meaning and intent from text or speech. NLU algorithms analyze input data to identify entities, relationships, sentiment, and context. It enables machines to understand and respond to user queries, commands, or requests accurately.\\n\\n2. Natural Language Generation (NLG): NLG, on the other hand, is concerned with the generation of human-like language by machines. It involves transforming structured data or information into natural language sentences or paragraphs. NLG algorithms take data as input and generate coherent and contextually appropriate responses, summaries, or reports. It is often used in applications such as chatbots, automated report generation, and personalized content creation.\\n\\nIn summary, NLU focuses on understanding human language, while NLG focuses on generating human-like language based on structured data or information. Both components play important roles in enabling effective communication between humans and machines.'),\n",
              "  HumanMessage(content='who is my name ?'),\n",
              "  AIMessage(content='Your name is Niken, as you mentioned earlier in our conversation. Is there anything specific you would like to know or discuss, Niken?'),\n",
              "  HumanMessage(content='whos win in the battle between gojo satoru vs ryomen sukuna ?'),\n",
              "  AIMessage(content='The battle between Gojo Satoru and Ryomen Sukuna is a fictional scenario from the manga and anime series \"Jujutsu Kaisen.\" As an AI language model, I don\\'t have access to the latest updates or story developments in the series. Therefore, I cannot provide a definitive answer on the outcome of that specific battle. It\\'s best to consult the source material or follow the series to find out what happens.')],\n",
              " 'text': 'The battle between Gojo Satoru and Ryomen Sukuna is a fictional scenario from the manga and anime series \"Jujutsu Kaisen.\" As an AI language model, I don\\'t have access to the latest updates or story developments in the series. Therefore, I cannot provide a definitive answer on the outcome of that specific battle. It\\'s best to consult the source material or follow the series to find out what happens.'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## retriever conversation\n",
        "- add new context about gojo vs sukana"
      ],
      "metadata": {
        "id": "X06tkaKi3nkq"
      },
      "id": "X06tkaKi3nkq"
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(\"https://beebom.com/jujutsu-kaisen-gojo-vs-sukuna/\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "GPKacWai36c8"
      },
      "id": "GPKacWai36c8",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(data)\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "9h8Y3OW-4D5M"
      },
      "id": "9h8Y3OW-4D5M",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embd = embedding=OpenAIEmbeddings()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_qdL0Oj_Mqz",
        "outputId": "fbb323b4-2bf2-4419-a2a1-d734de5322ba"
      },
      "id": "b_qdL0Oj_Mqz",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain.vectorstores.chroma.Chroma at 0x7ced5efa8070>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()\n",
        "qa_retriever = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
      ],
      "metadata": {
        "id": "sBIXp3Z_4STq"
      },
      "id": "sBIXp3Z_4STq",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_retriever(\"whos win in the battle between gojo satoru vs ryomen sukuna ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEX9DIE54xq2",
        "outputId": "c19ac30d-2b61-469a-d8f5-1c459ed9343b"
      },
      "id": "mEX9DIE54xq2",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'whos win in the battle between gojo satoru vs ryomen sukuna ?',\n",
              " 'chat_history': [HumanMessage(content='hi how are you'),\n",
              "  AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\"),\n",
              "  HumanMessage(content='my name is niken, i want to ask you something'),\n",
              "  AIMessage(content=\"Hello Niken! I'm here to answer any questions you may have. Please feel free to ask me anything, and I'll do my best to assist you.\"),\n",
              "  HumanMessage(content='do you know natural language processing (NLP) ?'),\n",
              "  AIMessage(content='Yes, I am familiar with natural language processing (NLP). NLP is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language to enable computers to comprehend and respond to human language in a meaningful way. NLP is used in various applications like chatbots, language translation, sentiment analysis, and more. Is there anything specific you would like to know about NLP?'),\n",
              "  HumanMessage(content='what is the different between natural language understanding and natural language generation ?'),\n",
              "  AIMessage(content='Natural Language Understanding (NLU) and Natural Language Generation (NLG) are two different components of natural language processing (NLP) that serve distinct purposes.\\n\\n1. Natural Language Understanding (NLU): NLU focuses on the comprehension and interpretation of human language by machines. It involves extracting meaning and intent from text or speech. NLU algorithms analyze input data to identify entities, relationships, sentiment, and context. It enables machines to understand and respond to user queries, commands, or requests accurately.\\n\\n2. Natural Language Generation (NLG): NLG, on the other hand, is concerned with the generation of human-like language by machines. It involves transforming structured data or information into natural language sentences or paragraphs. NLG algorithms take data as input and generate coherent and contextually appropriate responses, summaries, or reports. It is often used in applications such as chatbots, automated report generation, and personalized content creation.\\n\\nIn summary, NLU focuses on understanding human language, while NLG focuses on generating human-like language based on structured data or information. Both components play important roles in enabling effective communication between humans and machines.'),\n",
              "  HumanMessage(content='who is my name ?'),\n",
              "  AIMessage(content='Your name is Niken, as you mentioned earlier in our conversation. Is there anything specific you would like to know or discuss, Niken?'),\n",
              "  HumanMessage(content='whos win in the battle between gojo satoru vs ryomen sukuna ?'),\n",
              "  AIMessage(content='The battle between Gojo Satoru and Ryomen Sukuna is a fictional scenario from the manga and anime series \"Jujutsu Kaisen.\" As an AI language model, I don\\'t have access to the latest updates or story developments in the series. Therefore, I cannot provide a definitive answer on the outcome of that specific battle. It\\'s best to consult the source material or follow the series to find out what happens.'),\n",
              "  HumanMessage(content='whos win in the battle between gojo satoru vs ryomen sukuna ?'),\n",
              "  AIMessage(content=\"The outcome of the battle between Gojo Satoru and Ryomen Sukuna is that Sukuna emerges as the winner. Gojo, who was initially thought to be the winner, suddenly dies with Sukuna outsmarting him. This is a surprising turn of events, as Gojo's death is a loss to everyone in the fandom. However, some Sukuna fans are celebrating as Sukuna emerges as the champion of the battle.\")],\n",
              " 'answer': \"The outcome of the battle between Gojo Satoru and Ryomen Sukuna is that Sukuna emerges as the winner. Gojo, who was initially thought to be the winner, suddenly dies with Sukuna outsmarting him. This is a surprising turn of events, as Gojo's death is a loss to everyone in the fandom. However, some Sukuna fans are celebrating as Sukuna emerges as the champion of the battle.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.0 Similarity Search using Faiss\n",
        "- https://github.com/facebookresearch/faiss\n",
        "- https://python.langchain.com/docs/integrations/vectorstores/faiss"
      ],
      "metadata": {
        "id": "XOBfMUSDAY0W"
      },
      "id": "XOBfMUSDAY0W"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we will utilize the Faiss vector database, a powerful library for similarity search and recommendation, to create our song recommendation system. Faiss allows us to efficiently search through vast amounts of data to find courses that closely match the ones you’ve enjoyed or are interested in."
      ],
      "metadata": {
        "id": "5VeV1jeXFteE"
      },
      "id": "5VeV1jeXFteE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff8925f-4c21-4680-a9cd-3670ad4852b3",
      "metadata": {
        "id": "1ff8925f-4c21-4680-a9cd-3670ad4852b3"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import faiss\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "5BeRnQFKBtTA"
      },
      "id": "5BeRnQFKBtTA",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(r'/content/drive/MyDrive/Colab Notebooks/NLP_AI_Week_Ruangguru/spotify_songs.csv').dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "TP9JpZbWCtWn"
      },
      "id": "TP9JpZbWCtWn",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Cb8-F7tFDhLO",
        "outputId": "ec953e9a-883e-4194-deab-929c296d0f98"
      },
      "id": "Cb8-F7tFDhLO",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 track_id                                         track_name  \\\n",
              "0  6f807x0ima9a1j3VPbc7VN  I Don't Care (with Justin Bieber) - Loud Luxur...   \n",
              "1  0r7CVbZTWZgbTCYdfa2P31                    Memories - Dillon Francis Remix   \n",
              "\n",
              "  track_artist  track_popularity          track_album_id  \\\n",
              "0   Ed Sheeran                66  2oCs0DGTsRO98Gh5ZSl2Cx   \n",
              "1     Maroon 5                67  63rPSO264uRjW1X5E6cWv6   \n",
              "\n",
              "                                    track_album_name track_album_release_date  \\\n",
              "0  I Don't Care (with Justin Bieber) [Loud Luxury...               2019-06-14   \n",
              "1                    Memories (Dillon Francis Remix)               2019-12-13   \n",
              "\n",
              "  playlist_name             playlist_id playlist_genre  ... key  loudness  \\\n",
              "0     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   6    -2.634   \n",
              "1     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...  11    -4.969   \n",
              "\n",
              "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
              "0     1       0.0583        0.1020           0.00000    0.0653    0.518   \n",
              "1     1       0.0373        0.0724           0.00421    0.3570    0.693   \n",
              "\n",
              "     tempo  duration_ms  \n",
              "0  122.036       194754  \n",
              "1   99.972       162600  \n",
              "\n",
              "[2 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-045be859-00ea-4e32-9fe9-5d30b53e98f0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>track_id</th>\n",
              "      <th>track_name</th>\n",
              "      <th>track_artist</th>\n",
              "      <th>track_popularity</th>\n",
              "      <th>track_album_id</th>\n",
              "      <th>track_album_name</th>\n",
              "      <th>track_album_release_date</th>\n",
              "      <th>playlist_name</th>\n",
              "      <th>playlist_id</th>\n",
              "      <th>playlist_genre</th>\n",
              "      <th>...</th>\n",
              "      <th>key</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>valence</th>\n",
              "      <th>tempo</th>\n",
              "      <th>duration_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6f807x0ima9a1j3VPbc7VN</td>\n",
              "      <td>I Don't Care (with Justin Bieber) - Loud Luxur...</td>\n",
              "      <td>Ed Sheeran</td>\n",
              "      <td>66</td>\n",
              "      <td>2oCs0DGTsRO98Gh5ZSl2Cx</td>\n",
              "      <td>I Don't Care (with Justin Bieber) [Loud Luxury...</td>\n",
              "      <td>2019-06-14</td>\n",
              "      <td>Pop Remix</td>\n",
              "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
              "      <td>pop</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>-2.634</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1020</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0653</td>\n",
              "      <td>0.518</td>\n",
              "      <td>122.036</td>\n",
              "      <td>194754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0r7CVbZTWZgbTCYdfa2P31</td>\n",
              "      <td>Memories - Dillon Francis Remix</td>\n",
              "      <td>Maroon 5</td>\n",
              "      <td>67</td>\n",
              "      <td>63rPSO264uRjW1X5E6cWv6</td>\n",
              "      <td>Memories (Dillon Francis Remix)</td>\n",
              "      <td>2019-12-13</td>\n",
              "      <td>Pop Remix</td>\n",
              "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
              "      <td>pop</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>-4.969</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0373</td>\n",
              "      <td>0.0724</td>\n",
              "      <td>0.00421</td>\n",
              "      <td>0.3570</td>\n",
              "      <td>0.693</td>\n",
              "      <td>99.972</td>\n",
              "      <td>162600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-045be859-00ea-4e32-9fe9-5d30b53e98f0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-045be859-00ea-4e32-9fe9-5d30b53e98f0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-045be859-00ea-4e32-9fe9-5d30b53e98f0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-60c929a8-e4d9-414c-a7aa-69782255959f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60c929a8-e4d9-414c-a7aa-69782255959f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-60c929a8-e4d9-414c-a7aa-69782255959f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean = data[['track_name', 'track_artist']].drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "awseJWkAguKP"
      },
      "id": "awseJWkAguKP",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43dMer50Djme",
        "outputId": "d6a04175-e714-4f51-b96b-bff66bc5a119"
      },
      "id": "43dMer50Djme",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26229, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create corpus\n",
        "data_clean['corpus'] = data_clean['track_artist'] + \" \" + data_clean['track_name']\n",
        "\n",
        "song_corpus = data_clean['corpus']"
      ],
      "metadata": {
        "id": "6USkF_P2DkmD"
      },
      "id": "6USkF_P2DkmD",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorization\n",
        "vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3,3), min_df=5)\n",
        "X = vectorizer.fit_transform(song_corpus)"
      ],
      "metadata": {
        "id": "mrBtJUf3Dq8B"
      },
      "id": "mrBtJUf3Dq8B",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfZ8KJm2gXJv",
        "outputId": "09c487bb-7635-4513-a625-50e70b54ac9a"
      },
      "id": "LfZ8KJm2gXJv",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26229, 6183)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert sparse matrix to numpy array\n",
        "X_array = np.float32(X.toarray())\n",
        "\n",
        "# create vector database index\n",
        "index = faiss.IndexFlatL2(X_array.shape[1])\n",
        "\n",
        "# add vectors to the index\n",
        "index.add(X_array)"
      ],
      "metadata": {
        "id": "yd3qGc1hD4ig"
      },
      "id": "yd3qGc1hD4ig",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing search\n",
        "search_text = [\"coldplay\"]\n",
        "search_text_vector = vectorizer.transform(search_text)\n",
        "search_text_vector_array = np.float32(search_text_vector.toarray())\n",
        "\n",
        "distances, indices = index.search(search_text_vector_array, 5)\n",
        "\n",
        "for song_index in indices[0]:\n",
        "    print(f\"Song Title: {data_clean['track_name'][song_index]} from {data_clean['track_artist'][song_index]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgn3htPND8PV",
        "outputId": "a5c20511-68e0-421c-b3b8-2512ca83f8d2"
      },
      "id": "rgn3htPND8PV",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Song Title: O from Coldplay\n",
            "Song Title: Ink from Coldplay\n",
            "Song Title: Talk from Coldplay\n",
            "Song Title: Fix You from Coldplay\n",
            "Song Title: Magic from Coldplay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cerate function\n",
        "def recommend_course(title):\n",
        "    search_text = [title]\n",
        "    search_text_vector = vectorizer.transform(search_text)\n",
        "    search_text_vector_array = np.float32(search_text_vector.toarray())\n",
        "    distances, indices = index.search(search_text_vector_array, 5)\n",
        "\n",
        "    n_1 = f\"Song Title: {data_clean['track_name'][indices[0][0]]} from {data_clean['track_artist'][indices[0][0]]}\"\n",
        "    n_2 = f\"Song Title: {data_clean['track_name'][indices[0][1]]} from {data_clean['track_artist'][indices[0][1]]}\"\n",
        "    n_3 = f\"Song Title: {data_clean['track_name'][indices[0][2]]} from {data_clean['track_artist'][indices[0][2]]}\"\n",
        "\n",
        "    return n_1, n_2, n_3"
      ],
      "metadata": {
        "id": "8-og6j1VEGJU"
      },
      "id": "8-og6j1VEGJU",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_course(\"chainsmokers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mam0O3hER0n",
        "outputId": "a906814b-f7fe-4b52-997d-6bbc73e6bd58"
      },
      "id": "3Mam0O3hER0n",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Song Title: Young from The Chainsmokers',\n",
              " 'Song Title: Paris from The Chainsmokers',\n",
              " 'Song Title: Roses from The Chainsmokers')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_course(\"coldplay\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rb31VmBElsl",
        "outputId": "408ab3c7-4d16-4c6e-c456-6be4fc72b9cd"
      },
      "id": "7rb31VmBElsl",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Song Title: O from Coldplay',\n",
              " 'Song Title: Ink from Coldplay',\n",
              " 'Song Title: Talk from Coldplay')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_course(\"Denny Caknan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJfEWqxeEovX",
        "outputId": "39c1325b-b497-4652-b269-53ef0130dcd2"
      },
      "id": "YJfEWqxeEovX",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Song Title: İz from FG',\n",
              " 'Song Title: Kenny G from Matuê',\n",
              " \"Song Title: sunny from j'san\")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_course(\"Happy Asmara\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtAifXlGErjk",
        "outputId": "eede8703-d68a-40f2-8d05-93d88e05c150"
      },
      "id": "xtAifXlGErjk",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Song Title: Happy from ØMG',\n",
              " 'Song Title: Happy from Ashanti',\n",
              " 'Song Title: İz from FG')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GZGhJslsiVlQ"
      },
      "id": "GZGhJslsiVlQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}